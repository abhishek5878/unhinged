# === Database ===
DATABASE_URL=postgresql+asyncpg://apriori:apriori@localhost:5432/apriori
# pgvector extension must be enabled on this database

# === Redis ===
REDIS_URL=redis://localhost:6379/0

# === LLM ===
VLLM_BASE_URL=http://localhost:8000/v1
# vLLM server endpoint serving Llama 3.1 70B
VLLM_MODEL_NAME=meta-llama/Meta-Llama-3.1-70B-Instruct

# === Anthropic (for LangChain) ===
ANTHROPIC_API_KEY=sk-ant-...

# === Temporal.io ===
TEMPORAL_HOST=localhost:7233
TEMPORAL_NAMESPACE=apriori
TEMPORAL_TASK_QUEUE=apriori-simulations

# === LangSmith ===
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=ls__...
LANGCHAIN_PROJECT=apriori

# === Mem0 ===
MEM0_API_KEY=m0-...

# === Simulation Defaults ===
DEFAULT_NUM_SIMULATIONS=100
# Number of parallel Monte Carlo timelines per run
MAX_TIMELINE_TURNS=50
# Maximum conversation turns per simulated timeline
BELIEF_COLLAPSE_KL_THRESHOLD=2.0
# KL-divergence threshold for early warning
